"""
Network architectures for classification and pose prediction in Transformer modules.
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

from src.grid_sampler import grid_sample

from .coordinates import identity_grid


class TransformerLayer(nn.Module):
    def __init__(self, transformer=None, coords=identity_grid, downsample=1, 
                 grid_size_tf=None, ulim=None, vlim=None):
        """
        A wrapper class that applies a sequence of transformers followed by a coordinate transformation
        before passing the result through another network
        
        Args:
            transformer: nn.Module, transformer module returning a dict with the 
                         predicted transformation under the 'transform' key
            coords: Callable, coordinate transformation function
            downsample: int, input downsampling factor 
            grid_size_tf: (int, int), grid size for the transformer module
            ulim: (float, float), limits for the u coordinate
            vlim: (float, float), limits for the v coordinate
        """
        super().__init__()
        self.transformer = transformer
        self.coords = coords
        self.downsample = downsample
        self.grid_size_tf = grid_size_tf
        self.ulim = ulim
        self.vlim = vlim
    
    def forward(self, x, tf_output=False):
        """
        Args:
            x: torch.Tensor, input tensor
            tf_output: bool, whether to return dict with intermediate values generated by the transformer(s)
        
        Returns:
            (torch.Tensor, dict) if tf_output else torch.tensor, output of the network
        """
        grid_size = (x.shape[-2]//self.downsample, x.shape[-1]//self.downsample)
        grid_size_tf = self.grid_size_tf
        if grid_size_tf is None:
            grid_size_tf = x.shape[-2:]
        
        # input sampling grid: we start off with the grid representing the final coordinate transformation.
        # we then transform the grid using the transformation predicted by the transformer module.
        # you can convince yourself that resampling an image with a grid transformed by T_theta is equivalent
        # to first applying the inverse transformation T^{-1}_theta to the image, followed by the coordinate
        # transformation.
        if self.ulim is not None and self.vlim is not None:
            grid = self.coords(grid_size, device=x.device, ulim=self.ulim, vlim=self.vlim)
        else:
            grid = self.coords(grid_size, device=x.device)
        grid = grid.unsqueeze(0).expand(x.shape[0], -1, -1, -1)
        
        # predict the transformation from the input image and apply the predicted transformation to the grid
        if self.transformer is not None:
            tf_out = self.transformer(x, grid_size=grid_size_tf)
            transform = tf_out['transform']
            if type(transform) is list:
                transform = transform[-1]
            grid = transform(grid)
        else:
            tf_out = None 
        
        out = grid_sample(x, grid)
        if tf_output:
            return out, tf_out
        else:
            return out
    
# =================================================================================
# Helper functions that allow for cyclic (i.e., wrap-around) padding along an axis.
# We use cyclic padding when applying the CNN over coordinate systems that are
# periodic in at least one dimension (e.g., polar and log-polar coordinates).
# =================================================================================
    
def _pad1d(x, pad, mode):
    """1D padding.
    
    Args:
        x: torch.Tensor, input tensor
        pad: int, pad amount
        mode: str, one of 'constant', 'reflect', 'replicate', or 'cyclic'
    
    Returns:
        torch.Tensor, padded tensor
    """
    out = x
    if mode == 'cyclic':
        out = _cyclic_pad(out, pad=pad, axis=2)
    elif mode is not None:
        out = F.pad(out, (pad, pad), mode)
    return out


def _pad2d(x, pad, mode):
    """2D padding.
    
    Args:
        x: torch.Tensor, input tensor
        pad: int or (int, int), pad amount
        mode: str or (str, str), one of 'constant', 'reflect', 'replicate', or 'cyclic'
    
    Returns:
        torch.Tensor, padded tensor
    """
    if type(pad) is int:
        pad = (pad, pad)
    if type(mode) is str:
        mode = (mode, mode)
        
    wmode, hmode = mode
    wpad, hpad = pad
    out = x

    if wmode == 'cyclic':
        out = _cyclic_pad(out, pad=wpad, axis=3)
    elif wmode is not None:
        out = F.pad(out, (wpad, wpad, 0, 0), wmode)

    if hmode == 'cyclic':
        out = _cyclic_pad(out, pad=hpad, axis=2)
    elif hmode is not None:
        out = F.pad(out, (0, 0, hpad, hpad), hmode)

    return out


def _cyclic_pad(x, pad, axis):
    """Cyclic padding.
    
    Args:
        x: torch.Tensor, input tensor
        pad: int or (int, int), pad amount
        axis: int, axis along which to pad
    
    Returns:
        torch.Tensor, padded tensor
    """
    if type(pad) is int:
        pad = (pad, pad)
    if pad[0] == 0 and pad[1] == 0:
        return x
    if pad[1] > 0:
        left = x.narrow(axis, 0, pad[1])
    if pad[0] > 0:
        right = x.narrow(axis, x.shape[axis] - pad[0], pad[0])
    if pad[0] == 0:
        return torch.cat([x, left], axis)
    if pad[1] == 0:
        return torch.cat([right, x], axis)
    return torch.cat([right, x, left], axis)
    
# =========================================================
# Pose prediction modules
# =========================================================
    
def _centroid(heatmap, step, periodic=False):
    """
    Computes the centroid for each vector in a batch.
    
    If `periodic` is set to true, computes the centroid of points on the unit disk and then
    returns the scaled angle of the centroid.
    
    Args:
        heatmap: torch.Tensor, 2D tensor where the first dimension is the batch dimension
        step: float, interval between consecutive entries in tensor
        periodic: bool, whether the axis over which the centroid is to be computed is cyclic
    
    Returns:
        torch.Tensor, 1D tensor of centroids
    """
    rnge = torch.arange(heatmap.shape[1], dtype=torch.float, device=heatmap.device).mul_(step)
    rnge.add_(-rnge[-1]/2)  # center at 0
        
    if periodic:
        thetas = rnge.mul_(np.pi)
        xs = torch.cos(thetas)
        ys = torch.sin(thetas)
        x_c = heatmap.mv(xs)
        y_c = heatmap.mv(ys)
        return torch.atan2(y_c, x_c).div(np.pi)
    else:        
        return heatmap.mv(rnge)

    
class EquivariantPosePredictor(nn.Module):
    def __init__(self, 
                 in_channels, 
                 nf,
                 kernel_size=5,
                 strides=(2, 2),
                 periodic_u=False, 
                 periodic_v=False,
                 return_u=True,
                 return_v=True,
                 nonlin=lambda x: F.leaky_relu(x, 0.1, True),
                 **kwargs):
        """
        A translation-equivariant CNN for predicting transformation parameters.
        
        Args:
            in_channels: int, number of input channels
            nf: int, number of channels in convolutional layers
            kernel_size: int, kernel width in convolutional layers
            strides: (int, int), convolutional layer strides
            periodic_u: bool, whether the u coordinate is periodic
            periodic_v: bool, whether the v coordinate is periodic
            return_u: bool, whether to return the predicted u coordinate
            return_v: bool, whether to return the predicted v coordinate
            nonlin: Callable, nonlinearity
        """
        super().__init__()
        self.in_channels = in_channels
        self.nf = nf
        self.strides = strides
        self.kernel_size = kernel_size
        self.nonlin = nonlin              
        
        if not return_u and not return_v:
            raise ValueError('At least one of return_u and return_v must be true.')
        self.return_u = return_u
        self.return_v = return_v
    
        self.periodic_u = periodic_u
        self.periodic_v = periodic_v
        wmode = 'cyclic' if periodic_u else 'constant'
        hmode = 'cyclic' if periodic_v else 'constant'
        self.pad_mode = wmode, hmode
        
        k = kernel_size
        self.conv1 = nn.Conv2d(in_channels, nf, k, stride=strides[0], bias=False)
        self.bn1 = nn.BatchNorm2d(nf)
        self.conv2 = nn.Conv2d(nf, nf, k, stride=strides[1], bias=False)
        self.bn2 = nn.BatchNorm2d(nf)
        self.conv_u = nn.Conv1d(nf, 1, k, stride=1, bias=False)
        self.conv_v = nn.Conv1d(nf, 1, k, stride=1, bias=False)
        self.bias_u = nn.Parameter(torch.tensor(0.))
        self.bias_v = nn.Parameter(torch.tensor(0.))
    
    @staticmethod
    def _forward(x, module, deltas):
        vstride, ustride = module.stride
        vdelta, udelta = deltas
        return module(x), (vdelta*vstride, udelta*ustride)
    
    def forward(self, x):
        vdelta, udelta = 2./(x.shape[2]-1), 2./(x.shape[3]-1)
        
        out = _pad2d(x, (self.conv1.kernel_size[0]//2, self.conv1.kernel_size[1]//2), self.pad_mode)
        out, (vdelta, udelta) = self._forward(out, self.conv1, (vdelta, udelta))
        out = self.nonlin(self.bn1(out))
        
        out = _pad2d(out, (self.conv2.kernel_size[0]//2, self.conv2.kernel_size[1]//2), self.pad_mode)
        out, (vdelta, udelta) = self._forward(out, self.conv2, (vdelta, udelta))
        phi = self.nonlin(self.bn2(out))
        
        if self.return_u:
            out_u, _ = phi.max(2)
            out_u = _pad1d(out_u, self.conv_u.kernel_size[0]//2, self.pad_mode[0])
            out_u = self.conv_u(out_u).squeeze(1)
            heatmap_u = F.softmax(out_u, -1)
            u = _centroid(heatmap_u, udelta, self.periodic_u) + torch.tanh(self.bias_u)
            if not self.return_v:
                return u, heatmap_u
            
        if self.return_v:
            out_v, _ = phi.max(3)
            out_v = _pad1d(out_v, self.conv_v.kernel_size[0]//2, self.pad_mode[1])
            out_v = self.conv_v(out_v).squeeze(1)          
            heatmap_v = F.softmax(out_v, -1)
            v = _centroid(heatmap_v, vdelta, self.periodic_v) + torch.tanh(self.bias_v)
            if not self.return_u:
                return v, heatmap_v
        
        return (u, v), (heatmap_u, heatmap_v)
    
class DirectPosePredictor(nn.Module):
    def __init__(self,
                 in_channels,
                 nf,
                 kernel_size=5,
                 strides=(2, 2),
                 periodic_u=False,
                 periodic_v=False,
                 nonlin=lambda x: F.leaky_relu(x, 0.1, True),
                 num_outputs=1,
                 f_output=torch.tanh,
                 **kwargs):
        """
        A CNN that predicts transformation parameters "directly", i.e. in a non-equivariant manner.
        
        Args:
            in_channels: int, number of input channels
            nf: int, number of filters in convolutional layers
            kernel_size: int, kernel width in convolutional layers
            strides: (int, int), convolutional layer strides
            periodic_u: bool, whether the u coordinate is periodic
            periodic_v: bool, whether the v coordinate is periodic
            nonlin: Callable, nonlinearity between convolutional layers
            num_outputs: int, number of parameters to predict
            f_output: Callable, nonlinearity to apply to the output
        """
        super().__init__()
        self.in_channels = in_channels
        self.nf = nf
        self.strides = strides
        self.nonlin = nonlin  
        self.f_output = f_output
        self.kernel_size = kernel_size
        self.num_outputs = num_outputs

        self.periodic_u = periodic_u
        self.periodic_v = periodic_v
        wmode = 'cyclic' if periodic_u else 'constant'
        hmode = 'cyclic' if periodic_v else 'constant'
        self.pad_mode = wmode, hmode
        
        k = kernel_size
        self.conv1 = nn.Conv2d(in_channels, nf, k, stride=strides[0], bias=False)
        self.bn1 = nn.BatchNorm2d(nf)
        self.conv2 = nn.Conv2d(nf, nf, k, stride=strides[1], bias=False)
        self.bn2 = nn.BatchNorm2d(nf)
        self.fc = nn.Linear(nf*k*k, self.num_outputs, bias=True)
    
    def forward(self, x):        
        out = _pad2d(x, (self.conv1.kernel_size[0]//2, self.conv1.kernel_size[1]//2), self.pad_mode)
        out = self.conv1(out)
        out = self.nonlin(self.bn1(out))
        
        out = _pad2d(out, (self.conv2.kernel_size[0]//2, self.conv2.kernel_size[1]//2), self.pad_mode)
        out = self.conv2(out)
        phi = self.nonlin(self.bn2(out))
        
        k = self.kernel_size
        out = F.adaptive_max_pool2d(out, k).view(out.shape[0], self.nf*k*k)
        out = self.f_output(self.fc(out))
        if self.num_outputs == 1:
            return out[:, 0], None  # no heatmap
        return tuple([out[:, i] for i in range(self.num_outputs)]), tuple([None for i in range(self.num_outputs)])
    